---
title: "Aufgabenblatt 2"
fontsize: 11pt
header-includes: \usepackage[german]{babel}
output:
  pdf_document:
    highlight: tango
  html_document: default
fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, # -> Sollen Code Chunks im gerenderten Dokument angezeigt werden?
                      eval = TRUE, # -> Sollen R Code Chunks ausgefÃ¼hrt werden?
                      warning = FALSE, # -> Warnungen sollten nur am Ende zum Rendern auf FALSE gesetzt werden
                      message = FALSE) # -> Hinweise sollten nur am Ende zum Rendern auf FALSE gesetzt werden

library(tidyverse)
library(stringr)
library(magrittr)
library(dplyr)
library(fields)
```

1. Gegeben sei der nachstehende zweidimensionale Datensatz. FÃ¼hren Sie ein $K$-means Clustering mit $K=3$ unter Verwendung der euklidischen Distanz durch. Verwenden Sie die ersten drei Punkte als Anfangszentroiden. Geben Sie bei jeder Algorithmeniteration jeweils die Distanzen zwischen Zentroiden und allen Punkten an und berechnen Sie nach jeder Neuzuordnung der Punkte die verÃ¤nderten Zentroiden.  

<nbsp;>   | p1 | p2 | p3 | p4 | p5 | p6 | p7 | p8| p9 | p10 | p11 | p12
--------- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --  | -- 
x         | 2.0| 2.0| 2.0| 2.5| 2.5| 3.0| 4.0| 4.0| 4.5| 4.5| 4.5 | 4.5
y         | 1.0| 1.5| 2.0| 1.0| 2.0| 4.0| 1.0| 2.5| 1.0| 1.5| 2.5 | 3.0

```{r}
 dat <- tibble(
   x = c(2.0, 2.0, 2.0, 2.5, 2.5, 3.0, 4.0, 4.0, 4.5, 4.5, 4.5 , 4.5),
   y = c(1.0, 1.5, 2.0, 1.0, 2.0, 4.0, 1.0, 2.5, 1.0, 1.5, 2.5 , 3.0)
 )

# LÃ¶sung zu Aufgabe 1...

#create inital centers
centers<- dat[1:3,1:2] 
curCenters <- dat[2:4,1:2]

while(!isTRUE(all.equal(curCenters, centers))){
  curCenters <- centers
  print(rdist(centers, dat))
  dat <- mutate(dat,cluster=(apply(rdist(centers, dat),2,which.min)))
  for(i in 1:3){
    current <- filter(dat, cluster==i)
    centers[i,1] <- sum(current$x)/nrow(current)
    centers[i,2] <- sum(current$y)/nrow(current)
  }
}
ggplot(dat, aes(x=x, y=y)) + geom_point( aes(colour=cluster), size=3) +  scale_colour_gradientn(colours=rainbow(4))
```

2. Eine Schule mÃ¶chte ihre SchÃ¼ler nach den Leistungen bei zwei ZwischenprÃ¼fungen gruppieren. Es wird davon ausgegangen, dass es mindestens 2 Cluster von SchÃ¼lern gibt. Laden Sie die Datei `clustering-student-mat.csv` ein. Die Datei enthÃ¤lt zu jeder der beiden PrÃ¼fungen die Anzahl der erzielten Punktzahl fÃ¼r insgesamt 395 SchÃ¼ler.  
FÃ¼hren Sie je ein $K$-means-Clustering fÃ¼r alle $k\in \{2,3,\ldots,8\}$ durch. Stellen Sie die Clusterzuordnungen der Punkte in einem Streudiagramm (Scatter Plot) dar.

```{r}
# LÃ¶sung zu Aufgabe 2...
 student <- read_csv(str_c(dirname(getwd()), "/visualAnalytics/Data/clustering-student-mat.csv"))
k<-c(2:8)
for (j in k){
  clust<-kmeans(student,centers=j)
  student<-student %>% mutate(cluster = factor(clust$cluster))
  plt<-ggplot(student, aes(Exam1, Exam2, color = cluster, 
                                         fill = cluster))+
    geom_point()
  print(plt)
}

```

3. Ermitteln Sie fÃ¼r das Clustering aus Ausgabe 2 den optimalen Wert fÃ¼r die Anzahl der Cluster $K$ mithilfe des Silhouetten-Koeffizienten. Bewerten Sie das Ergebnis im Hinblick auf die ReprÃ¤sentativitÃ¤t der Zentroiden bezÃ¼glich ihres Clusters.

```{r}
# LÃ¶sung zu Aufgabe 3...
library(cluster)
k<-c(2:8)
for (j in k){
  clust<-kmeans(student,centers=j)
  student<-student %>% mutate(cluster = factor(clust$cluster))
  si <- silhouette(clust$cluster, dist(student))
  window(si)
  pdf(paste0(j, 'plot.pdf',sep=""))
  plot(si)
  dev.off()
}
#Repräsentativität der Zentroiden zu ihrem Cluster = Silhouetten-Koeffizienten sollten ähnlich sein
#2 bis 5 relativ durchwachsen, viele Mitglieder eines Clusters haben nahezu gleiche Entfernung zu anderen Clusterelementen wie geringste Entfernung zu Element aus anderem Cluster, die Werte meist im mittleren Bereich ca. um .50 herum -> mittelgute Repräsentativität der Cluster, auch negativ-Werte dabei -> mögliche Falsch-Klassifizierung
#ab 6 stärkere Repräsentativität der Zentroiden, da einzelne Durchschnittswerte für ein Cluster höher werden und Durchwachsenheit der Werte im Cluster abnimmt
# 8 beste Repräsentativität, aufgrund der ähnlichen Silhouettenwerte im jeweiligen Cluster
```

4. Gegeben sei die nachstehende Distanzmatrix. FÃ¼hren Sie agglomeratives hierarchisches Clustering mit _single_ und _complete_ Linkage durch. Stellen Sie das Ergebnis in einem Dendrogramm dar. Das Dendrogramm sollte die Reihenfolge des ZusammenfÃ¼gens der Punkte darstellen.
```{r}
dm <- tribble(~p1,~p2,~p3,~p4,~p5,
              0.00, 0.02, 0.90, 0.36, 0.53,
              0.02, 0.00, 0.65, 0.15, 0.24,
              0.90, 0.65, 0.00, 0.59, 0.45,
              0.36, 0.15, 0.59, 0.00, 0.56,
              0.53, 0.24, 0.45, 0.56, 0.00) %>% as.matrix()
rownames(dm) <- letters[1:5]
colnames(dm) <- letters[1:5]
knitr::kable(dm)

<<<<<<< HEAD
```{r}
# LÃ¶sung zu Aufgabe 4...

=======
library(ggdendro)
hc <- hclust(as.dist(dm), method = "single")
d_sl <- ggdendrogram(hc, rotate = F, size = 2)
d_sl
>>>>>>> 77e82fdfbb1219fb1129c8873f711898f57b688b
```

------

Datensatz fÃ¼r Aufgabe 2:  
http://isgwww.cs.uni-magdeburg.de/cv/lehre/VisAnalytics/material/exercise/datasets/clustering-student-mat.csv