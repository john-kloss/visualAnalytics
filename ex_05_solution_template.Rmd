---
title: "Aufgabenblatt 5"
fontsize: 11pt
header-includes: \usepackage[german]{babel}
output:
  pdf_document:
    highlight: haddock
  html_document: default
fig_caption: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      eval = TRUE,
                      warning = FALSE,
                      message = FALSE)
library(dplyr)
library(stringr)
library(tidytext)

```

**Block 1**: Entwickeln Sie einen Naive-Bayes-Klassifikator, der Spam-SMS erkennen kann. Der Lerndatensatz enthält für jede SMS den Text und das Label: Spam-SMS sind als `spam` und normale SMS als `ham` gekennzeichnet. Der Datensatz soll in eine Document-Term Matrix$^1$  umgewandelt werden, die als Input für den Naive-Bayes-Klassifikator dient.

1. Ermitteln Sie die Anzahl von `spam` und `ham` Nachrichten im Datensatz. Führen Sie eine Wort-Tokenisierung$^2$ durch. Sie können dazu z.B. `tidytext::unnest_tokens()` verwenden. Wandeln sie alle Großbuchstaben in Kleinbuchstaben um und entfernen Sie Satzzeichen wie ".", "," und ";". Entfernen Sie Stoppwörter wie "and", "of" und "or" aus dem SMS-Text. Sie können dazu Stoppwörterbücher wie `tidytext::stop_words` oder `tm::stopwords()` verwenden.

```{r}
spam <- read.csv(str_c(dirname(getwd()), "/visualAnalytics/Data/spam.csv"))

nrow(filter(spam, spam$type=="ham"))
nrow(filter(spam, spam$type=="spam"))

spam <- mutate(spam, text=as.character(text))
spam <- spam %>%
  tidytext::unnest_tokens(word, text)
spamJoin <- spam %>%
  anti_join(tidytext::stop_words, by = "word")

```

2. Ermitteln Sie die jeweils 10 am häufigsten vorkommenen Wörter für Spam- und Ham-SMS. Entfernen Sie Wörter, die insgesamt weniger als 2 mal in allen SMS vorkommen. Erstellen Sie eine Document-Term Matrix. Die Zeilen der Matrix entsprechen den SMS und die Spalten entsprechen allen Wörter, die in allen SMS vorkommen. Jeder Wert in der Matrix gibt an, ob ein bestimmtes Wort in einer bestimmten SMS vorkommt (`TRUE`/`FALSE`).

```{r}
h <-  as.data.frame(table(filter(spamJoin, type=="ham")))
h <- h[order(-h$Freq), , drop=FALSE]
h[1:10,]
h <- filter(h, Freq>1)
# create the table
dtm <- data.frame(row.names = 1:5572)
# insert the columns
for(i in 1:nrow(h)){
  dtm <- cbind(dtm,FALSE)
}
#name the columns
names(dtm) <- h[,2]

for(i in 1:nrow(spam)){
  
  j <- 1;

  while(!grepl(i+1,dimnames(spam[j,])[[1]])){
    #check if column exists
    if(!is.null(dtm[1,spam[i,2]])){
          dtm[1,spam[i,2]] <- TRUE
    }
  }
  dtm <- cbind(dtm, 1)
}

s <-  as.data.frame(table(filter(spamJoin, type=="spam")))
s <- s[order(-s$Freq), , drop=FALSE]
s[1:10,]
s <- filter(s, Freq>1)

```

3. Teilen Sie den Datensatz in eine Trainings- und und Testmenge im Verhältnis 70%:30% auf. Achten Sie darauf, dass die Verteilung von `spam` und `ham` in beiden Mengen ungefähr gleich ist. Verwenden Sie `set.seed()` zur Reproduzierbarkeit. Lernen Sie einen Naive-Bayes-Klassifikator auf der Trainingsmenge, z.B. mit `e1071:naiveBayes()`. Verwenden Sie das gelernte Modell zur Vorhersage von Spam in der Testmenge. Erstellen Sie eine Confusion Matrix und berechnen Sie Accuracy, Sensitivity und Specificity. Berechnen Sie die Verbesserung bzw. Verschlechterung bezüglich Accuracy, Sensitivity und Specificity des Modells im Vergleich zu einem simpleren Klassifikator, der für jede SMS stets die Mehrheitsklasse (`ham`) vorhersagen würde.

```{r}

```

------

**Block 2**: Bei der Generalversammlung der Vereinten Nationen kommen seit 1946 alle Mitgliedstaaten der Vereinten Nationen zusammen, um u.a. über Resolutionen zu beraten und abzustimmen. Derzeit gehören 193 Staaten den Vereinten Nationen an. Jeder dieser Mitgliedsstaaten hat bei Resolutionsabstimmungen zu Themen wie Abrüstung, internationale Sicherheit, humanitäre Hilfe und Menschenrechte im Rahmen der Generalversammlung genau eine Stimme.  
Der Datensatz für diese Aufgabe enthält den vollständigen Verlauf von Abstimmungen bei der Generalversammlung jedes Landes. Ist es möglich vorherzusagen, ob Deutschland bei einer Resolutionsabstimmung mit "Ja" oder "Nein" stimmt?

4. Stellen Sie die Anzahl der zur Abstimmung befandenen Resolutionen jedes Jahres in einem Liniendiagramm dar. In welchem Jahr gab es die meisten Abstimmungen und wie viele waren es? Berechnen Sie zwischen Deutschland und den USA für jedes Jahr den Anteil von gleichen Votierungen (Variable `vote`) für Resolutionen, im Folgenden `agreement` bezeichnet. Für das Jahr 2006 lag das Agreement zwischen beiden Staaten lediglich bei ca. 25% bei insgesamt 87 Abstimmungen. (_Hinweis: bis 1989 "Federal Republic of Germany"; ab 1989 "Germany"_) 
5. Erstellen Sie ein lineares Regressionsmodell, welches das Agreement zwischen beiden Staaten anhand des Jahres vorhersagt (`agreement ~ year`). Interpretieren Sie den Trend und den p-Wert des Regressionskoeffizienten für `year`. Überprüfen Sie die Aussage des Modells graphisch. Erstellen Sie eine Distanzmatrix zwischen allen Paaren von Staaten anhand ihrer Abstimmungshistorie. Berücksichtigen Sie dabei nur Staaten, die bei mindestens 70% aller Abstimmungen eine Stimme abgegeben haben. Ermitteln Sie die 5 Staaten, die am ähnlichsten bzw. am unähnlichsten zu Deutschland in Bezug auf die Abstimmungshistorie bei UN- Genralversammlungen sind.
6. Teilen Sie den Datensatz in eine Trainings- und und Testmenge im Verhältnis 75%:25% auf. Erstellen Sie einen $kNN$-Klassifikator mit $k=3$ (`caret::knn3Train()`) zur Vorhersage des Votums von Deutschland bei einer Abstimmung anhand der Votierungen der Länder ` 'Italy', 'Netherlands', 'United States of America', 'Israel', 'Cuba', 'India'`. Entfernen Sie dazu Abstimmungen, bei denen sich Deutschland enthalten hat (`vote=2` ("Abstain")) um eine binäre Zielvariable für `vote=1` ("Yes") und `vote=0` ("No") zu erhalten. Erstellen Sie die Confusion Matrix und berechnen Sie die Accuracy für das Modell. Erstellen Sie auf denselben Daten ein logistisches Regressionsmodell (`glm(..., family = "binomial")`) und vergleichen Sie die Accuracy mit der des $kNN$-Klassifikators.


```{r}

```

------
Datensatz für Block 1: http://isgwww.cs.uni-magdeburg.de/cv/lehre/VisAnalytics/material/exercise/datasets/spam.csv  
(adaptiert von http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)

Datensatz für Block 2: http://isgwww.cs.uni-magdeburg.de/cv/lehre/VisAnalytics/material/exercise/datasets/UNVotes.rds  
(adaptiert von https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/12379)  
- Data Dictionary / Codebook: http://isgwww.cs.uni-magdeburg.de/cv/lehre/VisAnalytics/material/exercise/datasets/UNVotes_Codebook.pdf

$^1$ https://en.wikipedia.org/wiki/Document-term_matrix  
$^2$ https://de.wikipedia.org/wiki/Tokenisierung, http://tidytextmining.com/tidytext.html
